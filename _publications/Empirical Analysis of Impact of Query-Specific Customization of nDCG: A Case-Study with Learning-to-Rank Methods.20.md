---
title: "Empirical Analysis of Impact of Query-Specific Customization of nDCG: A Case-Study with Learning-to-Rank Methods"
collection: publications
Authors: 'Shubhra Kanti Karmaker Santu, Parikshit Sondhi, ChengXiang Zhai'
date: 10/1/2020
venue: 'ACM CIKM'
paperurl: 'https://karmake2.github.io/files/Publications/2020/NDCG.pdf'
presentationurl: 'https://karmake2.github.io/files/Publications/2020/NDCG.pdf'
excerpt: ''
---
---
<a href='https://karmake2.github.io/files/Publications/2020/NDCG.pdf'>Download paper here</a>

<div style='display: flex; justify-content: center;'><img src='https://karmake2.github.io/files/Publications/2020/ndcg.png' alt='Image not Loading' style='height:300px;' align='middle'></div><br>

In most existing works, nDCG is  computed for a fixed cutoff $k$, i.e., $nDCG@k$ and some fixed discounting coefficient. Such a conventional query-independent way to compute nDCG does not accurately reflect the utility of search results perceived by an individual user and is thus non-optimal. In this paper, we conduct a case study of the impact of using query-specific nDCG on the choice of the optimal Learning-to-Rank (LETOR) methods, particularly to see whether using a query-specific nDCG would lead to a different conclusion about the relative performance of multiple LETOR methods than using the conventional query-independent nDCG would otherwise. Our initial results show that the relative ranking of LETOR methods using query-specific nDCG can be dramatically different from those using the query-independent nDCG at the individual query level, suggesting that query-specific nDCG may be useful in order to obtain more reliable conclusions in retrieval experiments.
