---
title: "NRF: A Naive Re-identification Framework. "
collection: publications
Authors: 'Shubhra Kanti Karmaker Santu, Vincent Bindschaedler, ChengXiang Zhai, Carl A. Gunter'
date: 10/1/2018
venue: 'WPES@ACM CCS'
paperurl: 'https://karmake2.github.io/files/Publications/2018/NRF.pdf'
presentationurl: 'https://karmake2.github.io/files/Publications/2018/NRF.pptx'
---

<a href='https://karmake2.github.io/files/Publications/2018/NRF.pdf'>Download paper here</a>

<div style='display: flex; justify-content: center;'><img src='https://karmake2.github.io/files/Publications/2018/NRF.png' alt='Image not Loading' style='height:300px;' align='middle'></div><br>

The promise of big data relies on the release and aggregation of data sets. When these data sets contain sensitive information about individuals, it has been scalable and convenient to protect the privacy of these individuals by de-identification. However, studies show that the combination of de-identified data sets with other data sets risks re-identification of some records. Some studies have shown how to measure this risk in specific contexts where certain types of public data sets (such as voter roles) are assumed to be available to attackers. To the extent that it can be accomplished, such analyses enable the threat of compromises to be balanced against the benefits of sharing data. For example, a study that might save lives by enabling medical research may be enabled in light of a sufficiently low probability of compromise from sharing de-identified data. In this paper, we introduce a general probabilistic re-identification framework that can be instantiated in specific contexts to estimate the probability of compromises based on explicit assumptions. We further propose a baseline of such assumptions that enable a first-cut estimate of risk for practical case studies. We refer to the framework with these assumptions as the Naive Re-identification Framework (NRF). As a case study, we show how we can apply NRF to analyze and quantify the risk of re-identification arising from releasing de-identified medical data in the context of publicly-available social media data. The results of this case study show that NRF can be used to obtain meaningful quantification of the re-identification risk, compare the risk of different social media, and assess risks of combinations of various demographic attributes and medical conditions that individuals may voluntarily disclose on social media.
