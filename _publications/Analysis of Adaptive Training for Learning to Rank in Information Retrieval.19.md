---
title: "Analysis of Adaptive Training for Learning to Rank in Information Retrieval"
collection: publications
Authors: 'Saar Kuzi, Sahiti Labhishetty, Shubhra Kanti Karmaker Santu, Prasad Pradip Joshi and ChengXiang Zhai'
date: 8/1/2019
venue: 'ACM CIKM [To appear] '
paperurl: 'https://karmake2.github.io/files/Publications/2019/Robust_LTR.pdf'
presentationurl: 'Coming soon'
excerpt: ''
---
---
<a href='https://karmake2.github.io/files/Publications/2019/Robust_LTR.pdf'>Download paper here</a>

<div style='display: flex; justify-content: center;'><img src='https://karmake2.github.io/files/Publications/2019/Robust_LTR.png' alt='Image not Loading' style='height:300px;' align='middle'></div><br>

Learning to Rank is an important framework used in search engines to optimize the combination of multiple features in a single ranking function. 
In the existing work on learning to rank, such a ranking function is often trained on a large set of different queries to optimize the overall performance on all of them. However, the optimal parameters to combine those features are generally query-dependent, making such a strategy of &quot;one size fits all&quot; non-optimal. Some previous works have addressed this problem by suggesting a query-level adaptive training for learning to rank with promising results. However, previous work has not analyzed the reasons for the improvement. In this paper, we present a Best-Feature Calibration (BFC) strategy for analyzing learning to rank models and use this strategy to examine the benefit of query-level adaptive training. Our results show that the benefit of adaptive training mainly lies in the improvement of the robustness of learning to rank in cases where it does not perform as well as the best single feature.  
