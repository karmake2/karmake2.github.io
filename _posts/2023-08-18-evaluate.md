---
title: "AI Assurance"
collection: posts
date: 2025-9-11
permalink: /posts/2025/9/assurance/
tags:
  - Research
  - Vision
---

AI assurance is vital to ensure systems act reliably and ethically, especially in this generative AI era. As AI gains autonomy in creating text, images, and decisions, assurance provides confidence that models behave as intended, respect societal norms, and avoid misinformation or bias. It safeguards against misuse, ensures transparency and accountability, and verifies that generative systems uphold accuracy, fairness, and trustworthinessâ€”protecting both users and institutions in an increasingly AI-driven world. To address these challenges, our lab focuses on three distinct themes under **AI Assurance**.

- **Theme 1: Assurance of Fairness:** Prevents bias and protects individuals from discriminatory outcomes.
  - Project: A Psycholinguistic Bias Ranking of Latest Large Language Models
- **Theme 2: Assurance of Interpretability:** Ensures that AI decisions can be understood, trusted, and audited by humans.
  - Project: ALIGN-SIM: A Task-Free Test Bed for Evaluating and Interpreting Sentence Embeddings
- **Theme 3: Assurance of Desired Skills:** Verifies that AI performs its intended functions accurately and consistently.
  - Project: Music Generation with Large Language Models

<br>
<br>

Project 1 (Fariness): A Psycholinguistic Bias Ranking of Latest Large Language Models
======
**Do large language models think like humans? Are they also prone to human-like cognitive biases?**

We just launched a new ranking system of LLMs based on their ability to resist cognitive biases with a large-scale study of **2.8M+ responses** across 8 well-known biases (Anchoring, Availability, Confirmation, Framing, Prospect Theory & more).

See which models resist bias the best, how prompt design changes outcomes, and why these matters for trustworthy decision making with AI.

Read our ArXiv paper detailing the experiments and results [here](https://arxiv.org/abs/2509.22856)

Explore the live rankings [here](https://bridgeai-lab.github.io/LLM-Ranking/)


<center>
  <div style='display: flex; justify-content: center;'><img src='/images/llmrank.png' alt='Image not Loading' style='height:300px;' align='middle'></div><br>
</center>
<br>
<br>

Project 2 (Interpretability): ALIGN-SIM: A Task-Free Test Bed for Evaluating and Interpreting Sentence Embeddings
======

Sentence embeddings play a pivotal role in a wide range of NLP tasks, yet evaluating and interpreting these real-valued vectors remains an open challenge to date, especially in a task-free setting. To address this challenge, we introduce a novel task-free test bed for evaluating and interpreting sentence embeddings. For more details, see [Our Huggingface Organization Page](https://huggingface.co/BridgeAI-Lab/ALIGN-Sim). For technical details, refer to our [EMNLP paper](https://aclanthology.org/2024.findings-emnlp.436/).

<br>
<br>


Project 3 (Desired Skills): Music Generation with Large Language Models
======

Details coming soon..
