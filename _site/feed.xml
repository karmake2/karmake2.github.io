<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-09-13T21:06:05-07:00</updated><id>/feed.xml</id><title type="html">Academic Homepage</title><subtitle>personal description</subtitle><author><name>Shubhra Kanti Karmaker (Santu)</name><email>sks0086@auburn.edu</email></author><entry><title type="html">Project CAMPeN: Multi-Perspective Narrative (MPN) Understanding / Braiding</title><link href="/posts/2023/08/CAMPeN/" rel="alternate" type="text/html" title="Project CAMPeN: Multi-Perspective Narrative (MPN) Understanding / Braiding" /><published>2023-08-22T00:00:00-07:00</published><updated>2023-08-22T00:00:00-07:00</updated><id>/posts/2023/08/Narrative</id><content type="html" xml:base="/posts/2023/08/CAMPeN/">&lt;p&gt;The objective of this research is to design and develop a novel human-AI collaborative framework that can braid the Overlapping, Unique, and Conflicting information from a pair of alternative narratives into a single coherent summary.&lt;/p&gt;

&lt;center&gt;
  &lt;div style=&quot;display: flex; justify-content: center;&quot;&gt;&lt;img src=&quot;/images/CAMPeN.png&quot; alt=&quot;Image not Loading&quot; style=&quot;height:450px;&quot; align=&quot;middle&quot; /&gt;&lt;/div&gt;&lt;br /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;overview-of-project-campen&quot;&gt;Overview of Project CAMPeN&lt;/h1&gt;
&lt;p&gt;Multi-Perspective Narratives (MPNs) are ubiquitous and very useful for verifying information from different alternative narratives, and thus, MPNs facilitate more informed decisions by providing a concise overall picture of the current situation. Despite great progress in the area of natural language processing (NLP), computers are still far from being able to analyze multi-perspective narratives accurately; addressing this limitation is the focus of this project.&lt;/p&gt;

&lt;p&gt;In this ongoing project, we are developing a novel human-AI collaborative framework called CAMPeN (``Collaborative Analytics of Multi-Perspective Narratives’’), where the AI, given multiple alternative narratives as input, first extracts a set of candidate clauses w.r.t. the Overlap-Unique-Conflict criteria, separately, in a zero-shot fashion. Next, the human actively verifies clauses that were labeled with low confidence by the AI. Finally, the machine braids the high-confidence/verified clauses to construct the ultimate Overlap-Unique-Conflict style summary, which will be presented to the user. The major benefits of the proposed framework are two-fold: 1) it enables domain experts in fields other than machine learning/NLP (e.g., a military general) to quickly dig out/verify interesting hypotheses from multiple alternative narratives/descriptions without worrying about the underlying computational techniques and thus, democratizes AI, and 2) it can quickly verify facts and claims about real-world events by analyzing alternative narratives and braid them into a single narrative with a higher degree of Information Assurance.&lt;/p&gt;

&lt;p&gt;This project adopts both zero-shot and reinforcement learning approaches for extracting overlapping, unique, and conflicting information from alternative narratives that can be trained in a self-supervised fashion without requiring a large collection of training data; therefore, the proposed framework needs minimal human supervision in comparison to the existing Multi-Document Summarization techniques. Additionally, the project borrows intuitions and insights from the classical set theory and applies the properties of set operators to develop novel reward/loss functions to enable effective training of reinforcement learning-based extraction networks.&lt;/p&gt;

&lt;h1 id=&quot;objectives-of-project-campen&quot;&gt;Objectives of Project CAMPeN&lt;/h1&gt;
&lt;p&gt;The proposed work includes the following objectives.&lt;/p&gt;

&lt;ol&gt;

&lt;li&gt;Design and develop a novel human-AI collaborative framework that can braid the Overlapping, Unique, and Conflicting information from a pair of alternative narratives into a single coherent summary.&lt;/li&gt;
    
&lt;li&gt;Conduct research on how to extract overlapping information from a pair of alternative narratives and paraphrase the overlap.&lt;/li&gt;
    
&lt;li&gt;Given a pair of alternative narratives as inputs, conduct research on how to extract unique information present exclusively in each input narrative and identify interesting, unique information.&lt;/li&gt;
    
&lt;li&gt;Conduct research on how to extract conflicting information from a pair of alternative narratives and how to resolve the conflict via effective human-AI collaboration.&lt;/li&gt;

&lt;li&gt;Design and Develop novel metrics for quantifying Author Influence by applying the proposed Human-AI collaborative framework.&lt;/li&gt;

&lt;li&gt;Conduct a thorough quantitative and qualitative evaluation of the proposed human-AI collaborative framework.&lt;/li&gt;

&lt;li&gt;Determine whether the proposed Human-AI collaborative framework performs similarly or differently in a language other than English.&lt;/li&gt;

 &lt;/ol&gt;</content><author><name>Shubhra Kanti Karmaker (Santu)</name><email>sks0086@auburn.edu</email></author><category term="Research" /><category term="Vision" /><summary type="html">The objective of this research is to design and develop a novel human-AI collaborative framework that can braid the Overlapping, Unique, and Conflicting information from a pair of alternative narratives into a single coherent summary.</summary></entry><entry><title type="html">Project PreSASDiL: Ad-Hoc Prediction Skill Acquisition</title><link href="/posts/2023/08/PreSASDiL/" rel="alternate" type="text/html" title="Project PreSASDiL: Ad-Hoc Prediction Skill Acquisition" /><published>2023-08-21T00:00:00-07:00</published><updated>2023-08-21T00:00:00-07:00</updated><id>/posts/2023/08/PreSASDiL</id><content type="html" xml:base="/posts/2023/08/PreSASDiL/">&lt;p&gt;This is an ongoing project where we are developing conversational AI techniques which are capable of acquiring new predictive skills on the fly through intuitive, natural conversations using self-directed learning.&lt;/p&gt;

&lt;h1 id=&quot;overview-of-project-presasdil&quot;&gt;Overview of Project “PreSASDiL”&lt;/h1&gt;
&lt;p&gt;In this project, we are utilizing Large Language Models (LLMs) to build a natural language interface between humans and the AutoML tools (like Scikit-Learn), which, in turn, facilitates acquiring new prediction skills via self-directed learning. The core technical challenges we are addressing in this project are the following:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Accurately understand and define the goal skill(s) to acquire (as defined by a human)&lt;/li&gt;
    
&lt;li&gt;Formulate a precise and relevant Machine Learning (ML) task.&lt;/li&gt;
    
&lt;li&gt;Curate data sets and assign model hyper-parameters accordingly.&lt;/li&gt;
    
&lt;li&gt;Train AutoML models to learn the skill.&lt;/li&gt;

&lt;li&gt;Apply the skill effectively.&lt;/li&gt;

&lt;/ol&gt;

&lt;center&gt;
  &lt;div style=&quot;display: flex; justify-content: center;&quot;&gt;&lt;img src=&quot;/images/VIDS.png&quot; alt=&quot;Image not Loading&quot; style=&quot;height:650px;&quot; align=&quot;middle&quot; /&gt;&lt;/div&gt;&lt;br /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Shubhra Kanti Karmaker (Santu)</name><email>sks0086@auburn.edu</email></author><category term="Research" /><category term="Vision" /><summary type="html">This is an ongoing project where we are developing conversational AI techniques which are capable of acquiring new predictive skills on the fly through intuitive, natural conversations using self-directed learning.</summary></entry><entry><title type="html">Project TI: Trust and Influence</title><link href="/posts/2023/08/TI/" rel="alternate" type="text/html" title="Project TI: Trust and Influence" /><published>2023-08-20T00:00:00-07:00</published><updated>2023-08-20T00:00:00-07:00</updated><id>/posts/2023/08/TI</id><content type="html" xml:base="/posts/2023/08/TI/">&lt;p&gt;This ongoing project aims to develop a novel metric to quantify an author’s influence in the narrative braiding process by comparing the final braided narrative against the individual author’s contribution in terms of the Overlap-Unique-Conflict clauses extracted by the CAMPeN framework.&lt;/p&gt;

&lt;center&gt;
  &lt;div style=&quot;display: flex; justify-content: center;&quot;&gt;&lt;img src=&quot;/images/Influence1.png&quot; alt=&quot;Image not Loading&quot; style=&quot;height:300px;&quot; align=&quot;middle&quot; /&gt;&lt;/div&gt;&lt;br /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;overview-of-project-ti&quot;&gt;Overview of Project “TI”&lt;/h1&gt;
&lt;p&gt;This project focused on developing a novel metric for quantifying author influence in the context of narrative braiding, which is largely an unexplored research area till now. By definition, a braided narrative is created from the contributions of multiple authors. For this thrust, we also assume that there is a separate entity called the editorial board that polishes and edits the raw contributions of individual authors and is in charge of creating the final braided narrative. Under these assumptions, we consider three scenarios for quantifying author influence: 1) Quantify Author Influence for Single Author Contribution - Single Braided Narrative Scenario, 2) Quantify Author Influence for Multiple Authors - Single Braided Narrative Scenario, and 3) Quantify Author Influence for Multiple Authors - Multiple Braided Narratives Scenario. Another basic idea here is that influential authors become more trustworthy over time and serve as reliable sources in the future.&lt;/p&gt;

&lt;center&gt;
  &lt;div style=&quot;display: flex; justify-content: center;&quot;&gt;&lt;img src=&quot;/images/Influence2.png&quot; alt=&quot;Image not Loading&quot; style=&quot;height:450px;&quot; align=&quot;middle&quot; /&gt;&lt;/div&gt;&lt;br /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Shubhra Kanti Karmaker (Santu)</name><email>sks0086@auburn.edu</email></author><category term="Research" /><category term="Vision" /><summary type="html">This ongoing project aims to develop a novel metric to quantify an author’s influence in the narrative braiding process by comparing the final braided narrative against the individual author’s contribution in terms of the Overlap-Unique-Conflict clauses extracted by the CAMPeN framework.</summary></entry><entry><title type="html">Project iLab</title><link href="/posts/2023/08/ilab/" rel="alternate" type="text/html" title="Project iLab" /><published>2023-08-19T00:00:00-07:00</published><updated>2023-08-19T00:00:00-07:00</updated><id>/posts/2023/08/iLab</id><content type="html" xml:base="/posts/2023/08/ilab/">&lt;p&gt;“iLab’’ is an ongoing project in my lab, where we are developing an artificial intelligence-based conversational framework to create dialog-based interactive laboratory experiences for middle school science students and teachers in the context of simulation-based science experiments.&lt;/p&gt;

&lt;center&gt;
  &lt;div style=&quot;display: flex; justify-content: center;&quot;&gt;&lt;img src=&quot;/images/iLab.png&quot; alt=&quot;Image not Loading&quot; style=&quot;height:500px;&quot; align=&quot;middle&quot; /&gt;&lt;/div&gt;&lt;br /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;overview-of-project-ilab&quot;&gt;Overview of Project “iLab”&lt;/h1&gt;
&lt;p&gt;The goal of this project is to develop a conversational, artificial intelligence-based ecosystem (iLab). Using advanced natural language understanding techniques, the intelligent agent at the center of the iLab ecosystem—SimPal—will work with middle school science teachers and students to provide a dialog-based interactive laboratory experience in the context of simulation-based science experiments. A key component of the framework is an intelligent conversational agent (SimPal) that engages with teachers in a dialog to solicit their instructional goals associated with simulation experiments and store them using a computational representation. The agent then uses this representation to facilitate and mediate an interactive dialog (powered by state-of-the-art large language models) with students as they run experiments to enhance their learning experience. The agent proactively asks students reflection questions, provide them with real-time customized feedback, tracks students’ progress, and then analyzes their responses and reports back to the teacher. Unlike existing intelligent tutoring systems and pedagogical conversational agents, SimPal can work with any off-the-shelf third-party simulations, a unique feature of this project.&lt;/p&gt;</content><author><name>Shubhra Kanti Karmaker (Santu)</name><email>sks0086@auburn.edu</email></author><category term="Research" /><category term="Vision" /><summary type="html">“iLab’’ is an ongoing project in my lab, where we are developing an artificial intelligence-based conversational framework to create dialog-based interactive laboratory experiences for middle school science students and teachers in the context of simulation-based science experiments.</summary></entry><entry><title type="html">Project Evaluate</title><link href="/posts/2023/08/evaluate/" rel="alternate" type="text/html" title="Project Evaluate" /><published>2023-08-18T00:00:00-07:00</published><updated>2023-08-18T00:00:00-07:00</updated><id>/posts/2023/08/evaluate</id><content type="html" xml:base="/posts/2023/08/evaluate/">&lt;p&gt;In this project, our main goal is to investigate how to make NLP/IR evaluation metrics more utility centric and robust.&lt;/p&gt;

&lt;h1 id=&quot;overview-of-project-evaluate&quot;&gt;Overview of Project “Evaluate”&lt;/h1&gt;
&lt;p&gt;Previous studies have shown that popular Natural Language Generation (NLG) and Information Retrieval (IR) and evaluation metrics, e.g., nDCG, ROUGE, MAP, are not robust and often do not correlate with the utility perceived by humans. In this project, our main goal is to investigate how to make NLP/IR evaluation metrics more utility centric.&lt;/p&gt;

&lt;ul&gt;

&lt;li&gt;&lt;b&gt;Natural Language Generation (NLG) Utility Evaluation:&lt;/b&gt; In ACL 2022, we proposed a gain-based automated metric called Sem-nCG, which is both rank and semantic aware, for evaluating extractive summarization tasks and showed that Sem-nCG exhibits a higher correlation with human judgments than the popular ROUGE metric. In the same year (EMNLP 2022), we proposed a new precision-recall style evaluation metric, called SEM-${F_1}$ (Semantic $F_1$), for evaluating the performance of the Overlap summary generation task. Experimental results show that the proposed SEM-$F_1$ metric yields a higher correlation with human judgment and inter-rater-agreement than the traditional ROUGE metric. Very recently, I proposed TELeR, a general taxonomy for benchmarking complex generation tasks using large language models (LLMs). TELeR enables meaningful comparisons across studies, establishing a common standard for prompt design and LLM evaluation; the taxonomy has received high attention from the industry and practitioners.&lt;/li&gt;&lt;br /&gt;


&lt;center&gt;
  &lt;div style=&quot;display: flex; justify-content: center;&quot;&gt;&lt;img src=&quot;/images/nCG.png&quot; alt=&quot;Image not Loading&quot; style=&quot;height:300px;&quot; align=&quot;middle&quot; /&gt;&lt;/div&gt;&lt;br /&gt;
&lt;/center&gt;
&lt;br /&gt;
 
&lt;li&gt;&lt;b&gt;Ranking Utility Evaluation:&lt;/b&gt; We recently proposed a novel framework for ranking evaluation with both upper and expected value normalization, where the expected value is estimated from a randomized ranking of the corresponding documents present in the evaluation set. Our proposed metric demonstrates an average of 21&amp;percnt; increase in Discriminatory Power and a 28&amp;percnt; increase in consistency. In a similar line of research, I previously performed a detailed evaluation of learning-to-rank methods for both Web search and E-Commerce search by exploiting multiple user feedback signals such as click rates, add-to-cart ratios, order rates, and revenue. The E-Commerce search study yielded multiple interesting insights and results that received significant attention from the search industry, including Walmart, Flipkart, @Unbxd, etc.&lt;/li&gt;

&lt;center&gt;
  &lt;div style=&quot;display: flex; justify-content: center;&quot;&gt;&lt;img src=&quot;/images/LBnorm.png&quot; alt=&quot;Image not Loading&quot; style=&quot;height:300px;&quot; align=&quot;middle&quot; /&gt;&lt;/div&gt;&lt;br /&gt;
&lt;/center&gt;
&lt;br /&gt;

&lt;/ul&gt;</content><author><name>Shubhra Kanti Karmaker (Santu)</name><email>sks0086@auburn.edu</email></author><category term="Research" /><category term="Vision" /><summary type="html">In this project, our main goal is to investigate how to make NLP/IR evaluation metrics more utility centric and robust.</summary></entry></feed>